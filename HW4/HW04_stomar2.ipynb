{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>STAT-542 HW4</center></h1>\n",
    "Sharvi Tomar (stomar2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 [35 Points] Regression and Optimization with Huber Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting linear regressions, outliers could significantly affect the fitting results. However, manually checking and removing outliers can be tricky and time consuming. Some regression methods address this problem by using a more robust loss function. For example, one such regression is to minimize the objective function\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\ell_\\delta(y_i - x_i^\\text{T} \\boldsymbol \\beta),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the loss function $\\ell_{\\delta}$ is the __Huber Loss__, defined as\n",
    "$$\n",
    "\\ell_\\delta( a ) =   \\begin{cases}\n",
    "    \\frac{1}{2} a^2       & \\quad \\text{if } |a| \\leq \\delta \\\\\n",
    "    \\delta(|a| - \\frac{1}{2} \\delta)  & \\quad \\text{o.w.}\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visualization that compares Huber loss with the $\\ell_2$ loss. We can see that the Huber loss assigns much less value when $y_i - x_i^\\text{T} \\boldsymbol \\beta$ is more extreme (outliers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Huber loss function\n",
    "def Huber(a, delta = 1):\n",
    "    if abs(a) <= delta:\n",
    "        return 0.5*(a**2)\n",
    "    else:\n",
    "        return delta*(abs(a) - 0.5*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot against L2\n",
    "import numpy as np\n",
    "x = np.arange (-4, 4, 0.01)\n",
    "\n",
    "huber_x = [Huber(el) for el in x]\n",
    "\n",
    "# Plotting \n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(huber_x)\n",
    "plt.plot(0.5*(x**2))\n",
    "plt.legend([\"Huber Loss\", \"OLS loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data from a simple linear model \n",
    "import random    \n",
    "random.seed(542)  \n",
    "\n",
    "n = 150\n",
    "x = np.random.uniform(0,1,n)\n",
    "X = np.stack((np.ones(n), x))\n",
    "y = np.matmul(np.transpose(X), [0.5, 1]) + np.random.normal(0, 1, n)\n",
    "  \n",
    "# create an outlier\n",
    "y[np.argmin(X[1])] = -30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) [5 pts] Fit an OLS model with the regular $\\ell_2$ loss. Report your coefficients (do not report other information). Although this is only one set of samples, but do you expect this estimator to be biased based on how we set up the observed data? Do you expect the parameter $\\beta_1$ to bias upwards or downwards? Explain your reason. Hint: is the outlier pulling the regression line slope up or down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model coefficients are:  [0.         2.42805681]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression().fit(np.transpose(X), y)\n",
    "\n",
    "print(\"The model coefficients are: \", model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. do you expect this estimator to be biased based on how we set up the observed data? \n",
    "2. Do you expect the parameter $\\beta_1$ to bias upwards or downwards? Explain your reason. Hint: is the outlier pulling the regression line slope up or down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) [10 pts] Define your own Huber loss function `huberLoss(b, trainX, trainY)` given a set of observed data with tuning parameter $\\delta = 1$. Here, `b` is a $p$-dim parameter vector, `trainX` is a $n \\times p$ design matrix and $trainY$ is the outcome. This function should return a scalar as the empirical loss. You can use our `Huber` function in your own code. After defining this loss function, use the `optim()` function to solve the parameter estimates. Finally, report your coefficients.  \n",
    "    - Use `b = (0, 0)` as the initial value.\n",
    "    - Use `BFGS` as the optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1\n",
    "\n",
    "def huberLoss(b, trainX, trainY):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) [20 pts] We still do not know which method performs better in this case. Let's use a simulation study to compare the two methods. Complete the following\n",
    "\n",
    "    * Set up a simulation for 1000 times. At each time, randomly generate a set of observed data, but also force the outlier with our code `y[which.min(X[, 2])] = -30`.\n",
    "    * Fit the regression model with $\\ell_2$ loss and Huber loss, and record the slope variable estimates.\n",
    "    * Make a side-by-side boxplot to show how these two methods differ in terms of the estimations. Which method seem to have more bias? and report the amount of bias based on your simulation. What can you conclude from the results? Does this match your expectation in part a)? Can you explain this (both OLS and Huber) with the form of loss function, in terms of what their effects are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 [65 Points] Scaling and Coordinate Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling issue** In the practice, we usually standardize each covariate/feature to mean 0 and standard deviation 1. Standardization is essential when we apply $\\ell_2$ and $\\ell_1$ penalty on the loss function, because if the covariates are with different scales, then they are penalized differently. Without prior information, we should prevent that from happening. Besides, scaling the data also help to make the optimization more stable, since the step size in many descent algorithms could be affected by the scale.\n",
    "\n",
    "In practice, after obtaining the coefficients fitted with scaled data, we want to recover the original coefficients of the unscaled data. For this question, we use the following intuition:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{Y - \\bar{Y}}{\\text{sd}_y} =&~ \\sum_{j=1}^p \\frac{X_j - \\bar{X}_j}{\\text{sd}_j} \\gamma_j \\\\\n",
    "Y =&~ \\underbrace{\\bar{Y} - \\sum_{j=1}^p \\bar{X}_j \\frac{\\text{sd}_y \\cdot \\gamma_j}{\\text{sd}_j}}_{\\beta_0} + \\sum_{j=1}^p X_j \\underbrace{\\frac{\\text{sd}_y \\cdot \\gamma_j}{\\text{sd}_j}}_{\\beta_j},\n",
    "\\end{align}\n",
    "\n",
    "  * In this equation, the first line is the model fitted with scaled and centered data. And we obtain the fitted parameters as $\\gamma_j$'s\n",
    "  * In the second line, the coefficients $\\beta_j$'s for the original data is recovered.\n",
    "  * When fitting the scaled and centered data, no intercept term is needed. \n",
    "\n",
    "Based on this relationship, we perform the following when fitting a linear regression:\n",
    "\n",
    "  * Center and scale both $\\mathbf{X}$ (column-wise) and $\\mathbf{y}$ and denote the processed data as $\\frac{Y - \\bar{Y}}{\\text{sd}_y}$ and $\\frac{X_j - \\bar{X}_j}{\\text{sd}_j}$ in the above formula. Make sure that the standard error of each variable is 1 after scaling. This means that you should use $N$, not $N-1$ when calculating the estimation of variance. \n",
    "  * Fit a linear regression using the processed data based on the no-intercept model, and obtain the parameter estimates $\\gamma_j$'s.\n",
    "  * Recover the original parameters $\\beta_0$ and $\\beta_j$'s.\n",
    "\n",
    "Use the following code to generate your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "n = 20\n",
    "p = 3\n",
    "\n",
    "# covariance matrix\n",
    "V = np.array([[0.3, 0.3, 0.3]] * 3)\n",
    "np.fill_diagonal(V, [1, 1, 1])\n",
    "  \n",
    "# generate data\n",
    "X_org = np.random.multivariate_normal([0, 0, 0], V, (3, 20))\n",
    "true_b = [1, 2, 0]\n",
    "y_org = np.matmul(X_org, true_b) + np.random.normal(0, 1, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) [10 pts] Fit an OLS estimator with the original data `Y_org` and `X_org` by `lm()`. Also, fit another OLS with scaled data by `lm()`. Report the coefficients/parameters. Then, transform coefficients from the second approach back to its original scale, and match with the first approach. Summarize your results in a single table: The rows should contain three methods: OLS, OLS Scaled, and OLS Recovered, and there should be four columns that represents the coefficients for each method. You can consider using the `kable` function, but it is not required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Instead of using the $lm()$ function, write your own coordinate descent code to solve the scaled problem. This function will be modified and used next week when we code the Lasso method. Complete the following steps:\n",
    "\n",
    "    - [10 pts] i) Given the loss function $L(\\beta) =  \\| y - X\\beta\\|^2$ or  $\\sum_{i=1}^n (y_i - \\sum_{j=0}^p x_{ij} \\beta_j)^2$ , derive the updating/calculation formula of coefficient $\\beta_j$, when holding all other covariates fixed. You must use LaTex to typeset your derivation with proper explaination of notations. Write down the formula (in terms of $y$, $x$ and $\\beta$'s) of residual $r$ before and after this update. Based on our lecture, how to make the update of $r$ computationally efficient? \n",
    "    \n",
    "    - [30 pts] ii) Implement this coordinate descent method with your own code to solve OLS with the scaled data. Print and report your **scaled coefficients** (no need to recover the original version) and compare with the result from the previous question.\n",
    "      - Do not use functions from any additional library.\n",
    "      - Start with a vec $\\boldsymbol \\beta = 0$.\n",
    "      - Run your coordinate descent algorithm for a maximum of maxitr = 100 iterations (while each iteration will loop through all variables). However, stop your algorithm if the $\\beta$ value of the current iteration is sufficiently similar to the previous one, i.e., $\\|\\beta^{(k)}− \\beta ^{(k−1)}\\|_1 \\leq$ tol. Set $tol = 1e-7$ where $\\| \\cdot \\|_1$ is the L1 distance.\n",
    "      \n",
    "    -  [5 pts] Make a plot to analyze the convergence of the coordinate descent. On the x-axis, we use the number of iteration. On the y-axis, use $\\log(\\text{Loss}_k - \\text{trueLoss})$. Here, \\text{trueLoss} is the emperical loss based on the true optimizor, which we can simply use the solution from the $lm()$ function (the scaled version). The $\\text{loss}_k$ is the loss function at the begining of the $k$-th iteration (Keep in mind that within each iteration, we will loop over all $\\beta_j$). If this plot displays a stragiht line, then we say that this algorithm has a linear convergence rate. Of course, this is at the log scale. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
